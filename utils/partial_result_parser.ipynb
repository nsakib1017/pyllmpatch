{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7f8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36cee36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "HASH_LINE_RE = re.compile(r\"Comparing files for hash:\\s+([0-9a-fA-F]+)\")\n",
    "FILE1_RE = re.compile(r\"File\\s*1\\s*:\\s*(.+)\")\n",
    "FILE2_RE = re.compile(r\"File\\s*2\\s*:\\s*(.+)\")\n",
    "FILE3_RE = re.compile(r\"File\\s*3\\s*:\\s*(.+)\")\n",
    "\n",
    "DIST_DECOMP_RE = re.compile(r\"Edit Distance \\(lookup vs decompiled\\)\\s*:\\s*(\\d+)\")\n",
    "DIST_REPAIRED_RE = re.compile(r\"Edit Distance \\(lookup vs repaired\\)\\s*:\\s*(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837cd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_edit_distance_log(log_path: str | Path):\n",
    "    \"\"\"\n",
    "    Parse the edit-distance log and return a list of dicts with:\n",
    "        - file_hash\n",
    "        - decompiled_file_name     (File 2)\n",
    "        - raw_file_name            (File 3)\n",
    "        - edit_distance_lookup_decompiled\n",
    "        - edit_distance_lookup_repaired\n",
    "    \"\"\"\n",
    "    log_path = Path(log_path)\n",
    "    if not log_path.is_file():\n",
    "        raise FileNotFoundError(f\"Log file not found: {log_path}\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    current_hash = None\n",
    "    file1 = None\n",
    "    file2 = None\n",
    "    file3 = None\n",
    "    d_decomp = None\n",
    "    d_repaired = None\n",
    "\n",
    "    with log_path.open(encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "\n",
    "            # --- HASH line ---\n",
    "            m_hash = HASH_LINE_RE.search(line)\n",
    "            if m_hash:\n",
    "                # Flush previous block\n",
    "                if current_hash and file2 and file3 and d_decomp is not None and d_repaired is not None:\n",
    "                    rows.append({\n",
    "                        \"file_hash\": current_hash,\n",
    "                        \"decompiled_file_name\": file2,\n",
    "                        \"raw_file_name\": file3,\n",
    "                        \"d_lookup_vs_decompiled\": d_decomp,\n",
    "                        \"d_lookup_vs_repaired\": d_repaired,\n",
    "                    })\n",
    "\n",
    "                current_hash = m_hash.group(1)\n",
    "                file1 = file2 = file3 = None\n",
    "                d_decomp = d_repaired = None\n",
    "                continue\n",
    "\n",
    "            # --- File name lines ---\n",
    "            m1 = FILE1_RE.search(line)\n",
    "            if m1:\n",
    "                file1 = m1.group(1).strip()\n",
    "                continue\n",
    "\n",
    "            m2 = FILE2_RE.search(line)\n",
    "            if m2:\n",
    "                file2 = m2.group(1).strip()\n",
    "                continue\n",
    "\n",
    "            m3 = FILE3_RE.search(line)\n",
    "            if m3:\n",
    "                file3 = m3.group(1).strip()\n",
    "                continue\n",
    "\n",
    "            # --- Distances ---\n",
    "            m_dec = DIST_DECOMP_RE.search(line)\n",
    "            if m_dec:\n",
    "                d_decomp = int(m_dec.group(1))\n",
    "                continue\n",
    "\n",
    "            m_rep = DIST_REPAIRED_RE.search(line)\n",
    "            if m_rep:\n",
    "                d_repaired = int(m_rep.group(1))\n",
    "                continue\n",
    "\n",
    "        # --- Final flush at EOF ---\n",
    "        if current_hash and file2 and file3 and d_decomp is not None and d_repaired is not None:\n",
    "            rows.append({\n",
    "                \"file_hash\": current_hash,\n",
    "                \"decompiled_file_name\": file2,\n",
    "                \"raw_file_name\": file3,\n",
    "                \"d_lookup_vs_decompiled\": d_decomp,\n",
    "                \"d_lookup_vs_repaired\": d_repaired,\n",
    "            })\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab8a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_to_dataframe(log_path: str | Path) -> pd.DataFrame:\n",
    "    rows = parse_edit_distance_log(log_path)\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46dd9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"edit_distance_results.txt\"  # adjust path\n",
    "\n",
    "df_parsed = parse_log_to_dataframe(log_file)\n",
    "# display(df_parsed.head())\n",
    "# print(f\"Parsed {len(df_parsed)} records.\")\n",
    "df_parsed.to_csv(\"edit_distance_results_new.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyllmpatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
